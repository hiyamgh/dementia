#!/usr/bin/env bash
#SBATCH --job-name=fotrcont
#SBATCH --account=hkg02
#SBATCH --partition=medium
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=2
#SBATCH --mem=16000
#SBATCH --mail-type=ALL
#SBATCH --mail-user=hkg02@mail.aub.edu
module load python/3
module load python/tensorflow-1.14.0
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 8 --meta_iters 5000 --eval_batch 15 --eval_iters 30 --model_num "39838" --dim_hidden "128, 64" --activation_fn "softmax" --weights_vector  "100, 1" --categorical_encoding "james"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 5 --eval_iters 20 --model_num "9808" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 100" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 15 --eval_iters 20 --model_num "14640" --dim_hidden "128, 64" --activation_fn "softmax" --weights_vector  "100, 1" --categorical_encoding "woe"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 10 --eval_iters 10 --model_num "11632" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "100, 1" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 10 --eval_iters 20 --model_num "20608" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 100" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 30 --model_num "24208" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 100" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 5 --eval_iters 20 --model_num "9784" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 1" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 5 --eval_iters 10 --model_num "8888" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 1" --categorical_encoding "mestimator"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 20 --model_num "23104" --dim_hidden "128, 64, 64" --activation_fn "relu" --weights_vector  "1, 1" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 20 --model_num "23320" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "10, 1" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 10 --eval_iters 30 --model_num "21532" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "100, 1" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 15 --eval_iters 20 --model_num "14482" --dim_hidden "128, 64" --activation_fn "sigmoid" --weights_vector  "1, 10" --categorical_encoding "james"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 10 --eval_iters 30 --model_num "13204" --dim_hidden "128, 64, 64" --activation_fn "relu" --weights_vector  "1, 1" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 15 --eval_iters 30 --model_num "16108" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 100" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 15 --eval_iters 20 --model_num "14620" --dim_hidden "128, 64" --activation_fn "softmax" --weights_vector  "10, 1" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/top10/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 20 --model_num "23288" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 1" --categorical_encoding "mestimator"  --logdir "FOML_trans_trained_models/top10/"
