#!/usr/bin/env bash
#SBATCH --job-name=fotrcont
#SBATCH --account=hkg02
#SBATCH --partition=normal
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=2
#SBATCH --mem=16000
#SBATCH --mail-type=ALL
#SBATCH --mail-user=hkg02@mail.aub.edu
module load python/3
module load python/tensorflow-1.14.0
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 20 --model_num "23111" --dim_hidden "128, 64, 64" --activation_fn "relu" --weights_vector  "1, 1" --categorical_encoding "woe"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 20 --model_num "23307" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 100" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 15 --eval_iters 10 --model_num "14283" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 1" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 20 --model_num "23289" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 1" --categorical_encoding "james"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 5 --eval_iters 10 --model_num "17015" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 100" --categorical_encoding "woe"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 15 --eval_iters 20 --model_num "15217" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "10, 1" --categorical_encoding "catboost"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 20 --model_num "22729" --dim_hidden "128, 64" --activation_fn "softmax" --weights_vector  "100, 1" --categorical_encoding "catboost"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 5 --eval_iters 10 --model_num "8929" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "100, 1" --categorical_encoding "catboost"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 10 --eval_iters 30 --model_num "21501" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 10" --categorical_encoding "james"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 15 --eval_iters 30 --model_num "16081" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 1" --categorical_encoding "catboost"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 8 --meta_iters 5000 --eval_batch 5 --eval_iters 10 --model_num "33231" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "100, 1" --categorical_encoding "glmm"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 20 --model_num "23281" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 1" --categorical_encoding "catboost"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 20 --model_num "23337" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "100, 1" --categorical_encoding "james"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 10 --eval_iters 30 --model_num "21493" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 10" --categorical_encoding "catboost"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 5000 --eval_batch 5 --eval_iters 20 --model_num "9799" --dim_hidden "128, 64, 64" --activation_fn "softmax" --weights_vector  "1, 10" --categorical_encoding "mestimator"  --logdir "FOML_trans_trained_models/"
python main_foml_trans.py --shots 10 --inner_batch 5 --inner_iters 10 --learning_rate 0.001 --meta_step 1.0 --meta_step_final 1.0 --meta_batch 4 --meta_iters 10000 --eval_batch 15 --eval_iters 20 --model_num "22751" --dim_hidden "128, 64" --activation_fn "swish" --weights_vector  "1, 1" --categorical_encoding "woe"  --logdir "FOML_trans_trained_models/"
