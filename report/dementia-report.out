\BOOKMARK [1][-]{section.1}{Data Sources}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Datasets Used}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Dementia Output}{section.1}% 3
\BOOKMARK [1][-]{section.2}{Split Into numeric and textual}{}% 4
\BOOKMARK [1][-]{section.3}{Numeric Features}{}% 5
\BOOKMARK [2][-]{subsection.3.1}{Informant and High Percentage of Missing}{section.3}% 6
\BOOKMARK [2][-]{subsection.3.2}{Nested Questions and High percentage of missing}{section.3}% 7
\BOOKMARK [2][-]{subsection.3.3}{Treating Features with High Percentage of Missing}{section.3}% 8
\BOOKMARK [2][-]{subsection.3.4}{Detecting Erroneous Values Inside Features}{section.3}% 9
\BOOKMARK [2][-]{subsection.3.5}{Working with Legal Features}{section.3}% 10
\BOOKMARK [2][-]{subsection.3.6}{Filtering Legal Features with Erroneous Values - Erroneous Code-Book}{section.3}% 11
\BOOKMARK [2][-]{subsection.3.7}{Detecting Outliers}{section.3}% 12
\BOOKMARK [2][-]{subsection.3.8}{Outlier Detection and Scaling}{section.3}% 13
\BOOKMARK [2][-]{subsection.3.9}{Feature Cross}{section.3}% 14
\BOOKMARK [1][-]{section.4}{Feature Selection}{}% 15
\BOOKMARK [2][-]{subsection.4.1}{Decision Tree Feature Importance}{section.4}% 16
\BOOKMARK [3][-]{subsubsection.4.1.1}{Select K Best Features}{subsection.4.1}% 17
\BOOKMARK [3][-]{subsubsection.4.1.2}{Deciding "K"}{subsection.4.1}% 18
\BOOKMARK [3][-]{subsubsection.4.1.3}{Selecting K Best Features}{subsection.4.1}% 19
\BOOKMARK [1][-]{section.5}{Oversampling and Undersampling}{}% 20
\BOOKMARK [1][-]{section.6}{Chapter 6: Precision, Recall, and F-measure}{}% 21
\BOOKMARK [1][-]{section.7}{Chapter 7:ROC Curves and Precision-Recall Curves}{}% 22
\BOOKMARK [2][-]{subsection.7.1}{ROC Curve}{section.7}% 23
\BOOKMARK [2][-]{subsection.7.2}{AUC}{section.7}% 24
\BOOKMARK [1][-]{section.8}{Chapter 8: Probability Scoring Methods}{}% 25
\BOOKMARK [2][-]{subsection.8.1}{Probability Metrics}{section.8}% 26
\BOOKMARK [2][-]{subsection.8.2}{LogLoss Score}{section.8}% 27
\BOOKMARK [1][-]{section.9}{Cross Validation for Imbalanced Datasets}{}% 28
\BOOKMARK [1][-]{section.10}{Chapter 10}{}% 29
\BOOKMARK [1][-]{section.11}{Chapter 12}{}% 30
\BOOKMARK [2][-]{subsection.11.1}{Oversampling}{section.11}% 31
\BOOKMARK [2][-]{subsection.11.2}{Undersampling Techniques}{section.11}% 32
\BOOKMARK [1][-]{section.12}{Data Transforms \(Hiyam\)}{}% 33
\BOOKMARK [2][-]{subsection.12.1}{Scaling Numeric Data \(chapter 17\)}{section.12}% 34
\BOOKMARK [2][-]{subsection.12.2}{Scaling Data with Outliers \(chapter 18\)}{section.12}% 35
\BOOKMARK [2][-]{subsection.12.3}{How to Encode Categorical Data \(chapter 19\)}{section.12}% 36
\BOOKMARK [2][-]{subsection.12.4}{How to Make Distributions Look More Gaussian \(chapter 20\)}{section.12}% 37
\BOOKMARK [1][-]{section.13}{Data Pre-Pocessing}{}% 38
\BOOKMARK [2][-]{subsection.13.1}{Imputation in Ordinal/Categorical Data}{section.13}% 39
\BOOKMARK [2][-]{subsection.13.2}{Imputation Currently Done}{section.13}% 40
\BOOKMARK [2][-]{subsection.13.3}{Scaling}{section.13}% 41
\BOOKMARK [2][-]{subsection.13.4}{Encoding Data}{section.13}% 42
\BOOKMARK [1][-]{section.14}{Advanced ML Evaluation Techniques}{}% 43
\BOOKMARK [2][-]{subsection.14.1}{Analysis of Predictive Models}{section.14}% 44
\BOOKMARK [2][-]{subsection.14.2}{Evaluation Using Traditional Metrics}{section.14}% 45
\BOOKMARK [2][-]{subsection.14.3}{Problem with Standard Evaluation Metrics}{section.14}% 46
\BOOKMARK [2][-]{subsection.14.4}{Solution: Risk Estimates}{section.14}% 47
\BOOKMARK [2][-]{subsection.14.5}{Ensuring Quality Of Risk Estimates}{section.14}% 48
\BOOKMARK [3][-]{subsubsection.14.5.1}{From Models to Risk Estimates}{subsection.14.5}% 49
\BOOKMARK [3][-]{subsubsection.14.5.2}{Measuring the Goodness of Risk Scores}{subsection.14.5}% 50
\BOOKMARK [3][-]{subsubsection.14.5.3}{Comparative Evaluation of Risk Estimates}{subsection.14.5}% 51
\BOOKMARK [2][-]{subsection.14.6}{Interpreting Classifier Outputs - FP Growth}{section.14}% 52
\BOOKMARK [2][-]{subsection.14.7}{Technicalities}{section.14}% 53
\BOOKMARK [2][-]{subsection.14.8}{Characterizing Prediction Mistakes}{section.14}% 54
\BOOKMARK [2][-]{subsection.14.9}{Comparing Classifier Predictions}{section.14}% 55
\BOOKMARK [1][-]{section.15}{Advanced ML Evaluation of Fake News Experiments}{}% 56
\BOOKMARK [2][-]{subsection.15.1}{Experiment 1}{section.15}% 57
\BOOKMARK [3][-]{subsubsection.15.1.1}{Mean Empirical Risks}{subsection.15.1}% 58
\BOOKMARK [3][-]{subsubsection.15.1.2}{Precision at Top K}{subsection.15.1}% 59
\BOOKMARK [3][-]{subsubsection.15.1.3}{Recall at Top K}{subsection.15.1}% 60
\BOOKMARK [3][-]{subsubsection.15.1.4}{Jaccard Similarity at Top K}{subsection.15.1}% 61
\BOOKMARK [3][-]{subsubsection.15.1.5}{ROC Curves}{subsection.15.1}% 62
