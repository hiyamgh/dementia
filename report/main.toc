\contentsline {section}{\numberline {1}Data Sources}{4}{section.1}%
\contentsline {subsection}{\numberline {1.1}Datasets Used}{4}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Dementia Output}{5}{subsection.1.2}%
\contentsline {section}{\numberline {2}Split Into numeric and textual}{5}{section.2}%
\contentsline {section}{\numberline {3}Numeric Features}{5}{section.3}%
\contentsline {subsection}{\numberline {3.1}Informant and High Percentage of Missing}{6}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Nested Questions and High percentage of missing}{6}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Treating Features with High Percentage of Missing}{7}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}Detecting Erroneous Values Inside Features}{8}{subsection.3.4}%
\contentsline {subsection}{\numberline {3.5}Working with Legal Features}{8}{subsection.3.5}%
\contentsline {subsection}{\numberline {3.6}Filtering Legal Features with Erroneous Values - Erroneous Code-Book}{8}{subsection.3.6}%
\contentsline {subsection}{\numberline {3.7}Detecting Outliers}{9}{subsection.3.7}%
\contentsline {subsection}{\numberline {3.8}Outlier Detection and Scaling}{9}{subsection.3.8}%
\contentsline {subsection}{\numberline {3.9}Erroneous Codebook}{10}{subsection.3.9}%
\contentsline {subsection}{\numberline {3.10}Treating Erroneous Values}{10}{subsection.3.10}%
\contentsline {subsection}{\numberline {3.11}Data Preprocessing}{11}{subsection.3.11}%
\contentsline {subsubsection}{\numberline {3.11.1}Imputing Missing Values}{11}{subsubsection.3.11.1}%
\contentsline {subsubsection}{\numberline {3.11.2}Scaling Features}{11}{subsubsection.3.11.2}%
\contentsline {section}{\numberline {4}Feature Selection}{11}{section.4}%
\contentsline {subsection}{\numberline {4.1}Decision Tree Feature Importance}{11}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Select K Best Features}{11}{subsection.4.2}%
\contentsline {subsubsection}{\numberline {4.2.1}Deciding "K"}{11}{subsubsection.4.2.1}%
\contentsline {subsubsection}{\numberline {4.2.2}Selecting K Best Features}{12}{subsubsection.4.2.2}%
\contentsline {section}{\numberline {5}Oversampling and Undersampling}{12}{section.5}%
\contentsline {subsection}{\numberline {5.1}Dealing With Mixed Variables}{12}{subsection.5.1}%
\contentsline {section}{\numberline {6}Cost-Sensitive Learning}{12}{section.6}%
\contentsline {subsection}{\numberline {6.1}Cost sensitive learning consists of the following steps:}{12}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}Tested sampling methods (using SMOTENC's sampling\_strategy options):}{13}{subsection.6.2}%
\contentsline {subsection}{\numberline {6.3}Tested class\_weights: (costs for each label), combination of suggestions from book and built-in options:}{13}{subsection.6.3}%
\contentsline {subsection}{\numberline {6.4}Probabilistic Models}{14}{subsection.6.4}%
\contentsline {subsubsection}{\numberline {6.4.1}Grid Search For Optimal Probability Threshold}{14}{subsubsection.6.4.1}%
\contentsline {subsubsection}{\numberline {6.4.2}Calibrated Models}{14}{subsubsection.6.4.2}%
\contentsline {subsubsection}{\numberline {6.4.3}Balanced Random Forest Results}{14}{subsubsection.6.4.3}%
\contentsline {subsubsection}{\numberline {6.4.4}Results}{15}{subsubsection.6.4.4}%
\contentsline {subsubsection}{\numberline {6.4.5}Results With Top 10 Features}{15}{subsubsection.6.4.5}%
\contentsline {subsubsection}{\numberline {6.4.6}Results With Top 20 Features}{16}{subsubsection.6.4.6}%
\contentsline {subsection}{\numberline {6.5}Classfication Models}{16}{subsection.6.5}%
\contentsline {subsubsection}{\numberline {6.5.1}Results}{16}{subsubsection.6.5.1}%
\contentsline {subsubsection}{\numberline {6.5.2}Results With Top 10 Features}{16}{subsubsection.6.5.2}%
\contentsline {subsubsection}{\numberline {6.5.3}Results With Top 20 Features}{16}{subsubsection.6.5.3}%
\contentsline {subsection}{\numberline {6.6}One-Class Classification}{16}{subsection.6.6}%
\contentsline {section}{\numberline {7}SHAP}{17}{section.7}%
\contentsline {subsection}{\numberline {7.1}Global SHAP Summary Values Results}{17}{subsection.7.1}%
\contentsline {subsection}{\numberline {7.2}Global SHAP Interaction Values}{19}{subsection.7.2}%
\contentsline {subsection}{\numberline {7.3}Multi-output Decision Plot for properly classified Rows}{20}{subsection.7.3}%
\contentsline {subsection}{\numberline {7.4}Decision Plot for Miss-classified Row}{22}{subsection.7.4}%
\contentsline {section}{\numberline {8}Chapter 6: Precision, Recall, and F-measure}{22}{section.8}%
\contentsline {section}{\numberline {9}Chapter 7:ROC Curves and Precision-Recall Curves}{22}{section.9}%
\contentsline {subsection}{\numberline {9.1}ROC Curve}{22}{subsection.9.1}%
\contentsline {subsection}{\numberline {9.2}AUC}{23}{subsection.9.2}%
\contentsline {section}{\numberline {10}Chapter 8: Probability Scoring Methods}{23}{section.10}%
\contentsline {subsection}{\numberline {10.1}Probability Metrics}{23}{subsection.10.1}%
\contentsline {subsection}{\numberline {10.2}LogLoss Score}{23}{subsection.10.2}%
\contentsline {section}{\numberline {11}Cross Validation for Imbalanced Datasets}{23}{section.11}%
\contentsline {section}{\numberline {12}Chapter 10}{23}{section.12}%
\contentsline {section}{\numberline {13}Chapter 12}{24}{section.13}%
\contentsline {subsection}{\numberline {13.1}Oversampling}{24}{subsection.13.1}%
\contentsline {subsection}{\numberline {13.2}Undersampling Techniques}{24}{subsection.13.2}%
\contentsline {section}{\numberline {14}Data Transforms (Hiyam)}{24}{section.14}%
\contentsline {subsection}{\numberline {14.1}Scaling Numeric Data (chapter 17)}{24}{subsection.14.1}%
\contentsline {subsection}{\numberline {14.2}Scaling Data with Outliers (chapter 18)}{24}{subsection.14.2}%
\contentsline {subsection}{\numberline {14.3}How to Encode Categorical Data (chapter 19)}{25}{subsection.14.3}%
\contentsline {subsection}{\numberline {14.4}How to Make Distributions Look More Gaussian (chapter 20)}{26}{subsection.14.4}%
\contentsline {section}{\numberline {15}Data Pre-Pocessing}{26}{section.15}%
\contentsline {subsection}{\numberline {15.1}Imputing Missing Values - Categorical Features}{26}{subsection.15.1}%
\contentsline {subsection}{\numberline {15.2}Imputing Missing Values - Numerical/Ordinal Features}{26}{subsection.15.2}%
\contentsline {subsection}{\numberline {15.3}Scaling - Numeric/Ordinal Features}{27}{subsection.15.3}%
\contentsline {subsection}{\numberline {15.4}Scaling - Categorical Features}{27}{subsection.15.4}%
\contentsline {section}{\numberline {16}Imputing Numerical Missing Data}{27}{section.16}%
\contentsline {subsection}{\numberline {16.1}Statistical Imputation}{27}{subsection.16.1}%
\contentsline {subsection}{\numberline {16.2}K Nearest Neighbors}{27}{subsection.16.2}%
\contentsline {subsection}{\numberline {16.3}Iterative Imputation}{27}{subsection.16.3}%
\contentsline {section}{\numberline {17}Imputing Categorical Missing Data}{28}{section.17}%
\contentsline {subsection}{\numberline {17.1}Mean Imputation}{28}{subsection.17.1}%
\contentsline {subsection}{\numberline {17.2}Imputation Using Most Frequent or (Zero/Constant Values)}{28}{subsection.17.2}%
\contentsline {subsection}{\numberline {17.3}Create a New Category (Random Category) for NAN Values}{28}{subsection.17.3}%
\contentsline {subsection}{\numberline {17.4} Adding a Variable To Capture NAN}{28}{subsection.17.4}%
\contentsline {subsection}{\numberline {17.5}Imputation Using Deep Learning (Datawig)}{28}{subsection.17.5}%
\contentsline {subsection}{\numberline {17.6}Regression Imputation}{28}{subsection.17.6}%
\contentsline {subsection}{\numberline {17.7}Imputation Using Interpolation}{29}{subsection.17.7}%
\contentsline {subsection}{\numberline {17.8}Multivariate Normal Imputation (MNVI)}{29}{subsection.17.8}%
\contentsline {subsection}{\numberline {17.9}Multiple Imputation by Chained Equations (MICE)}{29}{subsection.17.9}%
\contentsline {subsection}{\numberline {17.10}Stochastic regression imputation:}{30}{subsection.17.10}%
\contentsline {subsection}{\numberline {17.11}Extrapolation and Interpolation:}{30}{subsection.17.11}%
\contentsline {subsection}{\numberline {17.12}Hot-Deck Imputation}{30}{subsection.17.12}%
\contentsline {subsection}{\numberline {17.13}Some papers for handling missing categorical data (did not read them at length -- just the abstract)}{30}{subsection.17.13}%
\contentsline {section}{\numberline {18}Advanced ML Evaluation Techniques}{30}{section.18}%
\contentsline {subsection}{\numberline {18.1}Analysis of Predictive Models}{31}{subsection.18.1}%
\contentsline {subsection}{\numberline {18.2}Evaluation Using Traditional Metrics}{31}{subsection.18.2}%
\contentsline {subsection}{\numberline {18.3}Problem with Standard Evaluation Metrics}{32}{subsection.18.3}%
\contentsline {subsection}{\numberline {18.4}Solution: Risk Estimates}{32}{subsection.18.4}%
\contentsline {subsection}{\numberline {18.5}Ensuring Quality Of Risk Estimates}{33}{subsection.18.5}%
\contentsline {subsubsection}{\numberline {18.5.1}From Models to Risk Estimates}{33}{subsubsection.18.5.1}%
\contentsline {subsubsection}{\numberline {18.5.2}Measuring the Goodness of Risk Scores}{33}{subsubsection.18.5.2}%
\contentsline {subsubsection}{\numberline {18.5.3}Comparative Evaluation of Risk Estimates}{34}{subsubsection.18.5.3}%
\contentsline {subsection}{\numberline {18.6}Interpreting Classifier Outputs - FP Growth}{36}{subsection.18.6}%
\contentsline {subsection}{\numberline {18.7}Technicalities}{36}{subsection.18.7}%
\contentsline {subsection}{\numberline {18.8}Characterizing Prediction Mistakes}{37}{subsection.18.8}%
\contentsline {subsection}{\numberline {18.9}Comparing Classifier Predictions}{37}{subsection.18.9}%
\contentsline {section}{\numberline {19}Model Agnostic Meta Learning (MAML by Chelsea Finn)}{38}{section.19}%
\contentsline {subsection}{\numberline {19.1}Code Modifications}{38}{subsection.19.1}%
\contentsline {subsection}{\numberline {19.2}Modification of Data Generation Process}{40}{subsection.19.2}%
\contentsline {subsection}{\numberline {19.3}Incorporating FP Growth}{41}{subsection.19.3}%
\contentsline {subsection}{\numberline {19.4}Results}{43}{subsection.19.4}%
\contentsline {section}{\numberline {20}Meta Learning Vs. Shallow Models - FAKES}{44}{section.20}%
\contentsline {subsection}{\numberline {20.1}Methodology}{44}{subsection.20.1}%
\contentsline {subsection}{\numberline {20.2}Quantitative Results}{45}{subsection.20.2}%
\contentsline {subsection}{\numberline {20.3}Qualitative Results}{47}{subsection.20.3}%
\contentsline {subsection}{\numberline {20.4}Mean Empirical Risk Curves}{47}{subsection.20.4}%
\contentsline {subsection}{\numberline {20.5}Precisions Top K}{47}{subsection.20.5}%
\contentsline {subsection}{\numberline {20.6}Recalls Top K}{48}{subsection.20.6}%
\contentsline {subsection}{\numberline {20.7}ROC Curves}{48}{subsection.20.7}%
\contentsline {section}{\numberline {21}Meta Learning vs Shallow Models - Dementia Dataset}{48}{section.21}%
\contentsline {subsection}{\numberline {21.1}Cost Sensitive Learning in Neural Networks}{48}{subsection.21.1}%
\contentsline {subsection}{\numberline {21.2}Hyper Parameters}{50}{subsection.21.2}%
\contentsline {subsection}{\numberline {21.3}Winning Hyper Parameters}{51}{subsection.21.3}%
\contentsline {subsection}{\numberline {21.4}Quantitative Results - Without FP Growth}{52}{subsection.21.4}%
\contentsline {subsection}{\numberline {21.5}Insights}{54}{subsection.21.5}%
\contentsline {subsection}{\numberline {21.6}Quantitative Results - With FP Growth}{54}{subsection.21.6}%
\contentsline {subsection}{\numberline {21.7}Insights}{56}{subsection.21.7}%
\contentsline {subsection}{\numberline {21.8}Insights on With FP vs. Without FP}{56}{subsection.21.8}%
\contentsline {subsection}{\numberline {21.9}Insights about PPV}{57}{subsection.21.9}%
\contentsline {subsection}{\numberline {21.10}Qualitative Results}{57}{subsection.21.10}%
\contentsline {subsection}{\numberline {21.11}Mean Empirical Risk Curves}{57}{subsection.21.11}%
\contentsline {subsection}{\numberline {21.12}Precision at Top K}{59}{subsection.21.12}%
\contentsline {subsection}{\numberline {21.13}Recall at Top K}{60}{subsection.21.13}%
\contentsline {subsection}{\numberline {21.14}ROC Curves}{61}{subsection.21.14}%
